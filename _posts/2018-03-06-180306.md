---
layout: post
title: "一个下漫画的小玩意"
date: 2018.03.06 15:13
categories: scripts
tag: scripts
---
* content
{:toc}

为了深入提高老婆的做饭技能，带她参观学习了炒菜食谱视频《食戟之灵》。每天吃饭的时候看一集，感觉手中的窝窝头都有法式大餐的滋味呢。动画看完了不过瘾所以继续追漫画看，不过很久以前从100多话开始各种APP就不能看这个了，网上是有资源，但都是看一页点一下等半天才翻页这种愚蠢的操作，看了两话后实在是难以忍受，所以干脆写了个脚本把图片都下载下来。

## 此处应该有个题目

首先是资源出处。就是这个咯 [风之动漫](http://manhua.fzdm.com/058/)。
点开后发现每一话都是单独的链接，点进去后才只有一张图，看一张就要新开一页，看完一话还要被迫回到最开始的页面重新打开另一话，你知道移动端看这玩意得费劲到什么程度吗？！

不过看了下每话的网址，规律性还是挺强的嘛，比如：

232话就是 [http://manhua.fzdm.com/058/232](http://manhua.fzdm.com/058/232)

第一页就是 [http://manhua.fzdm.com/058/232/index_0.html](http://manhua.fzdm.com/058/232/index_0.html)

第二页就是 [http://manhua.fzdm.com/058/232/index_1.html](http://manhua.fzdm.com/058/232/index_1.html)

所以思路就是从初始页面得到每一话的URL，然后访问每一个URL，得到全部页码的URL，然后访问每一页得到图片地址下载图片。

全文完。

## ====大号分割线====

### 1

首先看这个网页如此普通，必定是个等闲之辈，加之个人写爬虫类脚本的基本礼仪，我们先不写请求头直接访问一下。此处用了python里的requests库，很简单的 `requests.get()` 方法试探一下。居然没啥反应直接正常得到了该得到的东西……那就这么写吧,<font color='#FF0033'>我是一个机器人</font>。

### 2

查看一下返回的乱七八糟的东西，每一话的地址就在里面排好了， <font color='#FF0000'><del>虽然我们已经知道了它的规律</del></font> ，先假装不知道，然后从中得到每一话的地址和对应话的名字。

![rCYPN.png](https://s1.ax2x.com/2018/03/06/rCYPN.png)

像这种规律的代码随随便便一个正则能把两个都找出来。

### 3

然后试着访问一下任意一话，发现该页的原码里竟然只有10页而没有全部页的URL，那我们就根据规律手动加页好了。

再然后是对应图片的地址，网页检察元素可以看到地址，在原码里看不到，显然是内嵌了脚本，只是没想到这个脚本竟然这么直接地放在原码里。说出来你们可能不信，他竟然是这么写的：<del>保护隐私还是不上图了，有兴趣的自己看吧</del>。

那我们同样用正则的方式，从他的脚本里把这个图片的地址找出来。
随机试了几个不同话的不同页，这段代码都是一样的。不得不说感谢每一个能把代码写成一样的强迫症朋友，真是解析的福音。<del>也可能他就是复制粘贴的</del>。

### 4

找到了图片地址，接下来就是下载了，图片是个二进制码，二进制格式打开文件写入保存就可以了。

简单地加上循环，设置一下保存路径，名字，以及纠错之类的就算完成了。

### 5

试运行发现偶尔会出现某些图中断的情况，做了些修改。

另外，竟然出现过网络连接超时的情况，但是没收集报错信息，不知道是不是被屏蔽了，反正加了些修改应该不会出现这个情况了。

脚本首次运行可以下载大部分图片，二次运行可以检查漏下的某些图片。

下好的漫画按话分成不同文件夹，然后传到云盘里就可以用移动端看了，对厨艺提升大有帮助。

![r1vJK.png](https://s1.ax2x.com/2018/03/06/r1vJK.png)

这个算是干货吗。