---
layout: post
title: "神经网络图像识别实践"
date: 2018.09.19 15:28
categories: script
tag: CNN
---
* content
{:toc}


近几月开始接触机器学习，重点关注了神经网络在图像识别方面的应用，从完全的0基础开始一路学习到完成一个差不多的练手项目，前后大约月余时间没有更新生信相关代码，不如就此来个机器学习的小结。

## 知识储备

接触机器学习领域的时间不长，不过也有其他同时期接触这领域的小伙伴，以我个人经验来看，统计学 > 线性代数 > 其他数学 > 所谓编程 ，只了解这么多，毕竟其他的我也不懂。不过统计学基础确实让我省了不少心，感觉很多奔走相告的大坑和乱码般的公式还是很顺眼的。难度不知道算不算难，见得多了自然就熟悉了。

第一条经验是拒绝西瓜书。花了银子买了西瓜书，翻看了几页觉得过于基础了，读后感是3分纯熟，5分有印象当复习，剩下2分有点新鲜感，所以这书看了不到半小时就翻完了，然后再也没碰过了。西瓜画的是挺好看的，特别是配上北京7月的温度。如果西瓜书上的理论基础都不能掌握个3-7成，感觉入这个门还是有些早。不过西瓜书厉害之处在于做了一个全面的纲要性的概述，帮助了解机器学习的几个领域细分和基础方法，以及详细的公式推导，建议当初学教材用，虽然这些公式学过概率论的应该都见过。

跳过西瓜书，貌似很难找到这么良心的中文读物了。接下来接触到的是斯坦福cs231n系列课程，计算机视觉领域大牛李飞飞执教，网易云或者墙外视频网站有视频资料，分不同学期版本，网易云有2016年秋季的中文字幕版。这个主要讲了卷积神经网络(CNN)，正是我关注的部分。课程中会介绍一些别的课程比如cs229、cs231a等的内容，这些没见过中文的了，不过有英文视频和文字版的资料，看起来比纯视频舒服些。这部分耗时大约70小时(注意力集中的30小时也够了)，中间被诸如8.0更新艾泽拉斯需要更多英雄等因素干扰，竟然拖了十几天。

github上有[cs231n 2018春季学期的主页](https://cs231n.github.io/)，上面有课程前部的文字资料。

基本上看完cs231n就有一战之力了，至少应该能仅用Numpy写一套3层以上的全连接网络(课程作业之一)，这是以后从基础层面了解NN的必备技能。


## 框架选择

理论基础后，实践环节有很多现成的框架帮助我们快速搭建网络模型和逆向梯度计算更新。框架优劣之争看个热闹，实际我选择了tensorflow和pytorch两个框架学习入门。二者的优势劣势一大堆技术分析帖，说的天花乱坠的看不懂，以小马过河之感受而言，我觉得tensorflow优势在于方法多，文档细，实例全；pytorch优势在于动态图层修改灵活，文档简便源码好看，简直pythonic。所以练手项目的最终成果用了tensorflow，初始搭建调试用了pytorch。至于什么分布式、大数据、跨平台之类的胡言乱语不太懂在说些什么。

tensorflow 安装是个大坑

pytorch 安装也不一定省心

千言万语汇成一句话，你有GPU吗？and 你GPU流弊吗？and 你用GPU吗？

如果上述判断为真的话，直接装GPU版的框架就好了，千万不要改动。为否的话，emm...还是想办法为真吧。

2个框架的 windows linux 环境GPU、CPU版本 8种组合我都折腾过了，心很累，超级累。

然而折腾的时候烦的不想写踩坑记录，现在也不记得具体犯什么错了。

最终解决方案： 只装GPU版本，只提供linux安装记录，因为windows的我也不知道成啥样了，虽然我在windows上调试

| tensorflow | python 3.6 | CUDA9.2 | cuDNN7.1 | 自行安装 |
| pytorch | python 3.6 | CUDA9.2 | - | [按官网提示安装](https://pytorch.org/get-started/locally/) |

---

## 练级之路 ##

成长总是痛苦而<del>不</del>快乐的，不能一口吃个胖子还不是因为懒。

所以我先从最基础的几个小玩意开始做起。

我的第一个操作是 线性分类器 -> 单层神经网络 -> 多层神经网络，就是课程作业里的那个破玩意的魔改版，具体方法可以开动脑筋自己随机些复杂度高的数据玩自己，全程numpy护航。先用SVM搞，再用softmax，再多加一层全连接层和relu或者sigmoid激活层搞。折腾几次熟悉下算法怎么写成代码、numpy怎么操作计算等基础代码组织。然后就会试着写2层、3层、4层网络，再然后就会发现一些代码重复，再再然后就试着写模块来代码重用，这时候就可以扼制写破轮子的冲动开始上别人的好轮子了。

第二个操作是 MNIST 手写数字识别。下载好MNIST数据，不禁被这数据的创建日期感动了。这里当时的我先试着写了把原始数据转成png图片的脚本，后来意识到当时是为了练习 图片—数据 间的转换操作，不过mnist图片是单通道的，实际上造成了对图片格式的误解，所以现在建议先了解一下各种图片类型的存储知识，然后再来图片操作。mnist数据集真是建立信心的好集，因为，只用线性分类器就能达到90%多的准确率真神奇，用单层神经网络能达到99%，所以这是一个不会犯错的数据集，怎么折腾都是对的。完成了这部分基本上对框架的操作有基本认识了，也对数据拆分合并加载有概念了，框架的tensor操作计算也大致了解了，网络模型搭建可能还不清楚，不过看到99+%的准确率还是挺满足的，特别是放在GPU上不到1分钟就搞定，再想想创建日期，真是快感动哭了。

第三个操作是 CIFAR10 数据集。还是图像分类操作，不过已经需要卷积网络才能达到一定准确率了。我在这部分开始单独写网络模型、数据加载、模型训练、结果验证部分，代码惨不忍睹，不过比我看过的所有教程简单多了，看强行教程贴真是耽误时间且侮辱智商，特别是tensorflow的非官方教程，简直起反作用，不过官方的CIFAR10实例太跳了，同样不建议直接看，回头看还是pytorch的代码可读性高，适合入门，应该能省不少时间。准确率嘛，基础版能到80+%，疑似过拟合版能到90+%。

第四个操作是 PASCAL VOC2012 数据集。这个就厉害了，不仅仅有图片分类(Classification)了，还有检测(Detection)、语义分割(Segmentation)等内容。图片大小也比之前厉害了不少，基本可以淘汰一批弱鸡显卡了（比如...T_T）。这个数据集的练手已经和要做的最终项目差不多了，从数据加载到网络构建训练验证已经需要调整一阵子了，不过这玩意数据量还是有些小，图片切切也很寒酸，所以准确率不是很满意啊。不过在做语义分割的时候已经开始接触FCN、ResNet之类的需要上采样、引入残差的网络结构了，读文献吧。惊喜的是因为图片大小不统一，可以练习到很多图片处理的奇淫巧技，吃一堑长一智。


## 项目部分 ##

暂且归类为医学图像识别吧，就是圈细胞。项目内容就是写一个自动识别目标细胞球的程序。

原图示意：

![imG7nK.png](https://s1.ax1x.com/2018/09/20/imG7nK.png)

![im8Rzt.png](https://s1.ax1x.com/2018/09/20/im8Rzt.png)

---
1. [原图裁剪(3520*3200)](https://s1.ax1x.com/2018/09/20/im2dNd.jpg)
2. [人工标记目标区域(3520*3200)](https://s1.ax1x.com/2018/09/20/imGLAe.jpg)
3. [神经网络标注结果(3520*3200)](https://s1.ax1x.com/2018/09/20/im2f4s.png)
4. [人工标注结果(3520*3200)](https://s1.ax1x.com/2018/09/20/imycFI.jpg)

对比原图来看，神经网络比人工还精细了不少。

原始图像大小 4908×3264 ，边缘不需要识别统一处理为 3520×3200 。需要在此范围内识别标记目标，可以默认为二分类。训练集大约3000张（原图+人工标记）组合,每张图切成11×10份的话还是挺可观的，旋转镜像处理容量可变为8倍，没搞随机中心剪裁。一块GTX 1080Ti，训练了30小时左右。


## 笔记+TIPS ##

---

**一些图像预处理的问题：**

 - 图像剪裁至目标大小 - 目标区域中心识别
   - 解决方案： 环形边缘识别 -> 中心识别
 - 图像亮度不一致 - 均一化
   - 解决方案： 多点采样均一化
 - 图像太大显存不够用
   - 解决方案1： 买买买
   - 解决方案2： 图像分割（320×320×11×10）

---

**网络模型搭建中的问题：**

 - 结构选择
   - 仿Unet构型，全卷积+残差。
 - 上采样层
   - 双线性插值，推荐
   - 逆Maxpool，不推荐
   - 经测试，反池化处理的最终结果在边缘区域有更多锯齿，不够平滑，计算过程数据丢失过多导致。
 - 归一化层
   - Instance normalization，推荐
   - Batch normalization，不推荐
   - 经测试，距圆心不同半径的区域特征不同，图片混为一集训练时batch normalization会模糊掉各部特征
   - Instance normalization收敛速度较BN耗时长1-2倍，还可以忍受
 - 卷积层
   - 卷就完了

---

**神经网络训练的问题：**

 - 调参就完了

---

**模型验证中的问题：**

 - 目标区域占比极小，通常为1%以下，需要特别关注目标区域的像素准确率，即漏报率，否则碰到0.1-%的极端图根本识别不了
 - 白色区域占比太大，总体像素准确率没有意义（全是白的都有99+%的准确率）
   - 解决方案：手动修改损失函数，**使loss值线性于目标区域准确率**（技术活）
 - 漏报率最终可降到0.8%以下，整体像素准确率99.7%

## 总结 ##

先学后练反思巩固提高。

项目里还有一些乱七八糟处理的脚本，比如图片定位剪裁、计算面积、制表绘图之类的就不一一列举了。服务用户，最后都打包写成傻瓜式的了，一键有难度，3键出报告还是可以的，覆盖多类极端需求，减少更新维护。

无知者无畏。
